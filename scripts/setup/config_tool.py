#!/usr/bin/env python3
"""
LocalLLM Configuration Tool
è¨­å®šã®ç¢ºèªã¨å¤‰æ›´ã®ãŸã‚ã®ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
import argparse
from pathlib import Path
import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from config.settings import get_settings

def show_current_config():
    """ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º"""
    print("ğŸ”§ LocalLLM ç¾åœ¨ã®è¨­å®š")
    print("=" * 50)
    
    try:
        settings = get_settings()
        
        print("ğŸ“‹ LLMè¨­å®š:")
        print(f"  ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {settings.default_model_path}")
        print(f"  ğŸ¯ æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³: {settings.max_tokens}")
        print(f"  ğŸŒ¡ï¸ Temperature: {settings.temperature}")
        print(f"  ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {settings.context_length}")
        
        print("\nğŸ’» CPU/GPUè¨­å®š:")
        print(f"  ğŸ–¥ï¸ GPUå±¤æ•°: {settings.n_gpu_layers} ({'CPUå°‚ç”¨' if settings.n_gpu_layers == 0 else 'GPUä½µç”¨'})")
        print(f"  ğŸ§µ CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {settings.n_threads}")
        print(f"  ğŸ’¾ RAMåˆ¶é™: {settings.max_memory_usage}GB")
        
        print("\nğŸ“Š å‡¦ç†è¨­å®š:")
        print(f"  ğŸ“„ æœ€å¤§å…¥åŠ›é•·: {settings.max_input_length:,} æ–‡å­—")
        print(f"  ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {settings.chunk_size:,} æ–‡å­—")
        print(f"  ğŸ”— ãƒãƒ£ãƒ³ã‚¯é‡è¤‡: {settings.chunk_overlap} æ–‡å­—")
        
        print("\nğŸ“ å‡ºåŠ›è¨­å®š:")
        print(f"  ğŸ“ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå½¢å¼: {settings.default_output_format}")
        print(f"  ğŸ“‚ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {settings.output_directory}")
        
        # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
        print("\nğŸŒ ç’°å¢ƒå¤‰æ•°:")
        env_vars = ['N_GPU_LAYERS', 'N_THREADS', 'MAX_MEMORY_USAGE', 'GPU_LAYERS']
        for var in env_vars:
            value = os.getenv(var, 'æœªè¨­å®š')
            print(f"  {var}: {value}")
            
    except Exception as e:
        print(f"âŒ è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def show_env_template():
    """ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¡¨ç¤º"""
    print("\nğŸ“ .env ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
    print("=" * 50)
    
    template = """# LLM Configuration
DEFAULT_MODEL_PATH = "models/llama-2-7b-chat.gguf"
MAX_TOKENS = 2048
TEMPERATURE = 0.7
CONTEXT_LENGTH = 2048
N_THREADS = 4
N_GPU_LAYERS = 0

# Processing Configuration  
MAX_INPUT_LENGTH = 100000
CHUNK_SIZE = 4000
CHUNK_OVERLAP = 200

# Memory Configuration
MAX_MEMORY_USAGE = 8
GPU_LAYERS = 0

# Output Configuration
DEFAULT_OUTPUT_FORMAT = "markdown"
OUTPUT_DIRECTORY = "output"
"""
    
    print(template)
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    env_file = Path('.env')
    if env_file.exists():
        print("âœ… .envãƒ•ã‚¡ã‚¤ãƒ«: å­˜åœ¨ã—ã¾ã™")
    else:
        print("âš ï¸ .envãƒ•ã‚¡ã‚¤ãƒ«: å­˜åœ¨ã—ã¾ã›ã‚“")
        create = input("ğŸ“ .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
        if create == 'y':
            env_file.write_text(template)
            print("âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

def check_performance_settings():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­")
    print("=" * 50)
    
    settings = get_settings()
    
    # CPUè¨­å®šãƒã‚§ãƒƒã‚¯
    import psutil
    cpu_cores = psutil.cpu_count(logical=False) or 4
    cpu_threads = psutil.cpu_count(logical=True) or 8
    
    print(f"ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
    print(f"  CPUã‚³ã‚¢æ•°: {cpu_cores}")
    print(f"  è«–ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°: {cpu_threads}")
    print(f"  è¨­å®šã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {settings.n_threads}")
    
    n_threads = settings.n_threads or 4
    if n_threads > cpu_threads:
        print("  âš ï¸ è¨­å®šã‚¹ãƒ¬ãƒƒãƒ‰æ•°ãŒã‚·ã‚¹ãƒ†ãƒ ã‚’è¶…ãˆã¦ã„ã¾ã™")
    elif n_threads <= cpu_cores:
        print("  âœ… é©åˆ‡ãªã‚¹ãƒ¬ãƒƒãƒ‰æ•°è¨­å®šã§ã™")
    
    # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
    ram_gb = psutil.virtual_memory().total / (1024**3)
    print(f"\nğŸ’¾ ãƒ¡ãƒ¢ãƒªæƒ…å ±:")
    print(f"  ç·RAM: {ram_gb:.1f}GB")
    print(f"  è¨­å®šåˆ¶é™: {settings.max_memory_usage}GB")
    
    max_memory = settings.max_memory_usage or 8
    if max_memory > ram_gb * 0.8:
        print("  âš ï¸ ãƒ¡ãƒ¢ãƒªè¨­å®šãŒé«˜ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    else:
        print("  âœ… é©åˆ‡ãªãƒ¡ãƒ¢ãƒªè¨­å®šã§ã™")
        
    # GPU/CUDA ãƒã‚§ãƒƒã‚¯
    print(f"\nğŸ–¥ï¸ GPU/CUDAæƒ…å ±:")
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        device_count = torch.cuda.device_count() if cuda_available else 0
        print(f"  CUDAåˆ©ç”¨å¯èƒ½: {'âœ… Yes' if cuda_available else 'âŒ No'}")
        print(f"  GPUæ•°: {device_count}")
        if cuda_available and device_count > 0:
            for i in range(device_count):
                name = torch.cuda.get_device_name(i)
                print(f"    GPU {i}: {name}")
    except ImportError:
        print("  âŒ PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    except Exception as e:
        print(f"  âš ï¸ GPUç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
    # GPUè¨­å®šã®æ¨å¥¨äº‹é …
    print(f"\nğŸ¯ æ¨å¥¨è¨­å®š:")
    n_gpu_layers = settings.n_gpu_layers or 0
    if n_gpu_layers > 0:
        try:
            import torch
            if not torch.cuda.is_available():
                print("  âš ï¸ GPUå±¤æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                print("    â†’ N_GPU_LAYERS=0 ã‚’æ¨å¥¨")
            else:
                print("  âœ… GPUè¨­å®šãŒæœ‰åŠ¹ã§ã™")
        except ImportError:
            print("  âš ï¸ GPUå±¤æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€PyTorchãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
            print("    â†’ N_GPU_LAYERS=0 ã‚’æ¨å¥¨")
    else:
        print("  âœ… CPUå°‚ç”¨è¨­å®šã§ã™")

def configure_gpu_settings():
    """GPUè¨­å®šã®å¯¾è©±çš„å¤‰æ›´"""
    print("ğŸ–¥ï¸ GPUè¨­å®šã®å¤‰æ›´")
    print("=" * 50)
    
    try:
        # GPUç’°å¢ƒã®æ¤œè¨¼
        try:
            sys.path.insert(0, str(project_root))
            from src.utils.gpu_validator import gpu_validator
            validation = gpu_validator.validate_gpu_environment()
            
            print("ğŸ” GPUç’°å¢ƒã®ç¢ºèª:")
            print(f"  CUDAåˆ©ç”¨å¯èƒ½: {'âœ… Yes' if validation['cuda_available'] else 'âŒ No'}")
            print(f"  GPUæ•°: {validation['gpu_count']}")
            
            if validation['gpu_info']:
                for gpu in validation['gpu_info']:
                    print(f"    GPU {gpu['id']}: {gpu['name']} ({gpu['memory_gb']}GB)")
                    
            print(f"\nğŸ¯ æ¨å¥¨è¨­å®š:")
            rec = validation['recommended_settings']
            print(f"  GPUå±¤æ•°: {rec['n_gpu_layers']}")
            print(f"  CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {rec['n_threads']}")
            print(f"  ç†ç”±: {rec['reason']}")
            
        except ImportError:
            print("âš ï¸ GPUæ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœªåˆ©ç”¨")
            validation = None
            
        # ç¾åœ¨ã®è¨­å®šè¡¨ç¤º
        settings = get_settings()
        print(f"\nğŸ“‹ ç¾åœ¨ã®è¨­å®š:")
        print(f"  GPUå±¤æ•°: {settings.n_gpu_layers}")
        print(f"  CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {settings.n_threads}")
        
        # è¨­å®šå¤‰æ›´ã®é¸æŠè‚¢
        print(f"\nğŸ”§ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
        print("1. CPUå°‚ç”¨ï¼ˆæ¨å¥¨ãƒ»å®‰å…¨ï¼‰")
        print("2. GPUå°‘é‡ä½¿ç”¨ï¼ˆ4-8å±¤ï¼‰")
        print("3. GPUä¸­é‡ä½¿ç”¨ï¼ˆ16-24å±¤ï¼‰")
        print("4. GPUæœ€å¤§ä½¿ç”¨ï¼ˆ32å±¤ï¼‰")
        print("5. ã‚«ã‚¹ã‚¿ãƒ è¨­å®š")
        print("6. æ¨å¥¨è¨­å®šã‚’é©ç”¨")
        print("7. æˆ»ã‚‹")
        
        choice = input("\né¸æŠ (1-7): ").strip()
        
        new_settings = {}
        
        if choice == "1":
            new_settings = {"n_gpu_layers": 0, "n_threads": 4}
            print("ğŸ’» CPUå°‚ç”¨è¨­å®šã‚’é¸æŠ")
        elif choice == "2":
            new_settings = {"n_gpu_layers": 8, "n_threads": 4}
            print("ğŸ–¥ï¸ GPUå°‘é‡ä½¿ç”¨è¨­å®šã‚’é¸æŠ")
        elif choice == "3":
            new_settings = {"n_gpu_layers": 20, "n_threads": 2}
            print("ğŸ–¥ï¸ GPUä¸­é‡ä½¿ç”¨è¨­å®šã‚’é¸æŠ")
        elif choice == "4":
            new_settings = {"n_gpu_layers": 32, "n_threads": 2}
            print("ğŸ–¥ï¸ GPUæœ€å¤§ä½¿ç”¨è¨­å®šã‚’é¸æŠ")
        elif choice == "5":
            # ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
            try:
                gpu_layers = int(input("GPUå±¤æ•° (0-50): "))
                threads = int(input("CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•° (1-16): "))
                new_settings = {"n_gpu_layers": gpu_layers, "n_threads": threads}
                print(f"ğŸ”§ ã‚«ã‚¹ã‚¿ãƒ è¨­å®š: GPU{gpu_layers}å±¤, CPU{threads}ã‚¹ãƒ¬ãƒƒãƒ‰")
            except ValueError:
                print("âŒ ç„¡åŠ¹ãªå…¥åŠ›ã§ã™")
                return
        elif choice == "6":
            if validation and validation['recommended_settings']:
                rec = validation['recommended_settings']
                new_settings = {
                    "n_gpu_layers": rec['n_gpu_layers'],
                    "n_threads": rec['n_threads']
                }
                print(f"ğŸ¯ æ¨å¥¨è¨­å®šã‚’é©ç”¨: GPU{rec['n_gpu_layers']}å±¤")
            else:
                print("âŒ æ¨å¥¨è¨­å®šãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return
        elif choice == "7":
            return
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return
            
        # è¨­å®šã®ä¿å­˜
        if new_settings:
            update_env_file(new_settings)
            print(f"âœ… è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ:")
            print(f"   GPUå±¤æ•°: {new_settings['n_gpu_layers']}")
            print(f"   CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {new_settings['n_threads']}")
            print("ğŸ’¡ å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ã«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def update_env_file(new_settings):
    """ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°"""
    env_path = project_root / ".env"
    
    # æ—¢å­˜ã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    env_lines = []
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            env_lines = f.readlines()
    
    # è¨­å®šã‚’æ›´æ–°
    updated_lines = []
    settings_updated = set()
    
    for line in env_lines:
        line = line.strip()
        if line.startswith("N_GPU_LAYERS") and "n_gpu_layers" in new_settings:
            updated_lines.append(f"N_GPU_LAYERS = {new_settings['n_gpu_layers']}\n")
            settings_updated.add("n_gpu_layers")
        elif line.startswith("N_THREADS") and "n_threads" in new_settings:
            updated_lines.append(f"N_THREADS = {new_settings['n_threads']}\n")
            settings_updated.add("n_threads")
        else:
            updated_lines.append(line + "\n" if line else "\n")
    
    # æ–°ã—ã„è¨­å®šã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    for key, value in new_settings.items():
        if key not in settings_updated:
            if key == "n_gpu_layers":
                updated_lines.append(f"N_GPU_LAYERS = {value}\n")
            elif key == "n_threads":
                updated_lines.append(f"N_THREADS = {value}\n")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(updated_lines)

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ"""
    parser = argparse.ArgumentParser(description="LocalLLM Configuration Tool")
    parser.add_argument("--show-config", action="store_true", help="ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º")
    parser.add_argument("--show-template", action="store_true", help=".envãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¡¨ç¤º")
    parser.add_argument("--check-performance", action="store_true", help="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­ã‚’å®Ÿè¡Œ")
    parser.add_argument("--gpu-config", action="store_true", help="GPUè¨­å®šãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º")
    parser.add_argument("--set-cpu-only", action="store_true", help="CPUå°‚ç”¨è¨­å®šã«å¤‰æ›´")
    parser.add_argument("--set-gpu-layers", type=int, metavar="N", help="GPUå±¤æ•°ã‚’è¨­å®š")
    parser.add_argument("--set-threads", type=int, metavar="N", help="CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’è¨­å®š")
    return parser.parse_args()

def quick_set_cpu_only():
    """CPUå°‚ç”¨è¨­å®šã¸ã®ç´ æ—©ã„å¤‰æ›´"""
    print("ğŸ’» CPUå°‚ç”¨è¨­å®šã¸ã®å¤‰æ›´")
    print("=" * 50)
    
    new_settings = {"n_gpu_layers": 0, "n_threads": 4}
    update_env_file(new_settings)
    
    print("âœ… CPUå°‚ç”¨è¨­å®šã«å¤‰æ›´ã—ã¾ã—ãŸ:")
    print("   GPUå±¤æ•°: 0")
    print("   CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: 4")
    print("ğŸ’¡ å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ã«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")

def quick_set_gpu_layers(layers: int, threads = None):
    """GPUå±¤æ•°ã®ç´ æ—©ã„è¨­å®š"""
    print(f"ğŸ–¥ï¸ GPUè¨­å®šã®å¤‰æ›´ï¼ˆ{layers}å±¤ï¼‰")
    print("=" * 50)
    
    # åŸºæœ¬çš„ãªæ¤œè¨¼
    if layers < 0 or layers > 50:
        print("âŒ GPUå±¤æ•°ã¯0-50ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„")
        return
        
    if threads is None:
        threads = 2 if layers > 0 else 4
    
    new_settings = {"n_gpu_layers": layers, "n_threads": threads}
    
    # GPUç’°å¢ƒç¢ºèªï¼ˆè­¦å‘Šã®ã¿ï¼‰
    if layers > 0:
        try:
            import torch
            if not torch.cuda.is_available():
                print("âš ï¸ è­¦å‘Š: CUDAæœªå¯¾å¿œç’°å¢ƒã§GPUè¨­å®šã‚’é©ç”¨ã—ã¾ã™")
                print("   ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€CPUå°‚ç”¨ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã‚Œã¾ã™")
        except ImportError:
            print("âš ï¸ è­¦å‘Š: PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§GPUè¨­å®šã‚’é©ç”¨ã—ã¾ã™")
    
    update_env_file(new_settings)
    
    print(f"âœ… GPUè¨­å®šã‚’å¤‰æ›´ã—ã¾ã—ãŸ:")
    print(f"   GPUå±¤æ•°: {layers}")
    print(f"   CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {threads}")
    print("ğŸ’¡ å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ã«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    args = parse_arguments()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    if args.show_config:
        show_current_config()
        return
    elif args.show_template:
        show_env_template()
        return
    elif args.check_performance:
        check_performance_settings()
        return
    elif args.set_cpu_only:
        quick_set_cpu_only()
        return
    elif args.set_gpu_layers is not None:
        quick_set_gpu_layers(args.set_gpu_layers, args.set_threads)
        return
    elif args.gpu_config:
        configure_gpu_settings()
        return
    
    # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
    print("ğŸ› ï¸ LocalLLM Configuration Tool")
    print("=" * 50)
    
    try:
        while True:
            print("\nğŸ“‹ ãƒ¡ãƒ‹ãƒ¥ãƒ¼:")
            print("1. ğŸ“Š ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º")
            print("2. ğŸ“ .envãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¡¨ç¤º/ä½œæˆ")
            print("3. âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­")
            print("4. ğŸ–¥ï¸ GPUè¨­å®šã‚’å¤‰æ›´")
            print("5. âŒ çµ‚äº†")
            
            choice = input("\né¸æŠ (1-5): ").strip()
            
            if choice == "1":
                show_current_config()
            elif choice == "2":
                show_env_template()
            elif choice == "3":
                check_performance_settings()
            elif choice == "4":
                configure_gpu_settings()
            elif choice == "5":
                print("ğŸ‘‹ è¨­å®šãƒ„ãƒ¼ãƒ«ã‚’çµ‚äº†ã—ã¾ã™")
                break
            else:
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
                
    except (KeyboardInterrupt, EOFError):
        print("\nğŸ‘‹ è¨­å®šãƒ„ãƒ¼ãƒ«ã‚’çµ‚äº†ã—ã¾ã™")

if __name__ == "__main__":
    main()
