#!/usr/bin/env python3
"""
LLM Processor for Technical Translation Integration
Real Llama 2 LLM integration for technical document translation
"""

import time
from typing import Dict, Any, Optional
from pathlib import Path
from loguru import logger

try:
    from src.summarizer_enhanced import LLMSummarizer
    from config.settings import Settings
    from config.llama2_config import LLAMA2_MODEL_PATH, LLAMA2_GENERATION_CONFIG
    llm_available = True
except ImportError as e:
    logger.warning(f"LLM components not available: {e}")
    llm_available = False


class LLMProcessor:
    """
    Real LLM processor for technical translation system.
    Integrates Llama 2 for high-quality technical document translation.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """
        Initialize LLM processor with Llama 2.
        
        Args:
            model_path: Path to the model file. Uses default Llama 2 if None.
        """
        self.model_path = Path(model_path) if model_path else LLAMA2_MODEL_PATH
        self.settings = Settings()
        self.summarizer: Optional[LLMSummarizer] = None
        self.is_loaded = False
        
        # Try to load the model
        self._initialize_llm()
    
    def _initialize_llm(self) -> bool:
        """Initialize the LLM model."""
        if not llm_available:
            logger.warning("‚ö†Ô∏è LLM components not available")
            return False
            
        if not self.model_path.exists():
            logger.warning(f"‚ö†Ô∏è Model file not found: {self.model_path}")
            logger.info("üí° Run 'python download_llama2.py' to download Llama 2 7B")
            return False
        
        try:
            logger.info("ü§ñ Initializing Llama 2 for technical translation...")
            self.summarizer = LLMSummarizer(
                model_path=str(self.model_path),
                settings=self.settings
            )
            self.is_loaded = True
            logger.success("‚úÖ Llama 2 LLM processor initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize LLM: {e}")
            logger.info("üí° Consider using a smaller model or increasing RAM")
            return False
    
    def translate_technical_text(self, english_text: str, doc_type: str = "datasheet") -> Dict[str, Any]:
        """
        Translate technical English text to Japanese using Llama 2.
        
        Args:
            english_text: English technical text to translate
            doc_type: Document type (datasheet, manual, paper, etc.)
            
        Returns:
            Translation result with metadata
        """
        if not self.is_loaded or not self.summarizer:
            return {
                'japanese_translation': "‚ö†Ô∏è LLM„ÅåÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì„ÄÇ„É¢„ÉÉ„ÇØÁøªË®≥„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
                'processing_time': 0.0,
                'confidence_score': 0.0,
                'llm_used': False
            }
        
        start_time = time.time()
        
        # Create specialized technical translation prompt
        specialized_prompt = self._create_technical_prompt(english_text, doc_type)
        
        try:
            # Use LLM for high-quality translation
            logger.info(f"üîÑ Processing technical translation ({len(english_text)} chars)")
            
            # Generate Japanese translation using LLM
            japanese_translation = self.summarizer.summarize_english_to_japanese(
                english_text=specialized_prompt
            )
            
            processing_time = time.time() - start_time
            
            # Calculate confidence score based on output quality
            confidence_score = self._calculate_confidence(japanese_translation, english_text)
            
            logger.success(f"‚úÖ Technical translation completed in {processing_time:.2f}s")
            
            return {
                'japanese_translation': japanese_translation,
                'processing_time': processing_time,
                'confidence_score': confidence_score,
                'llm_used': True,
                'model_name': self.model_path.name,
                'word_count': len(english_text.split()),
                'translation_length': len(japanese_translation)
            }
            
        except Exception as e:
            logger.error(f"‚ùå LLM translation failed: {e}")
            return {
                'japanese_translation': f"‚ùå LLMÁøªË®≥„Ç®„É©„Éº: {str(e)}",
                'processing_time': time.time() - start_time,
                'confidence_score': 0.0,
                'llm_used': False,
                'error': str(e)
            }
    
    def _create_technical_prompt(self, text: str, doc_type: str) -> str:
        """Create specialized prompt for technical translation."""
        
        # Document type specific instructions
        doc_instructions = {
            'datasheet': "„Éá„Éº„Çø„Ç∑„Éº„ÉàÂΩ¢Âºè„Åß„ÄÅÊäÄË°ì‰ªïÊßò„Å®ÁâπÊÄß„ÇíÊ≠£Á¢∫„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
            'manual': "ÊäÄË°ì„Éû„Éã„É•„Ç¢„É´ÂΩ¢Âºè„Åß„ÄÅÊìç‰ΩúÊâãÈ†Ü„Å®‰ªïÊßò„ÇíÂàÜ„Åã„Çä„ÇÑ„Åô„ÅèÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ", 
            'paper': "Â≠¶Ë°ìË´ñÊñáÂΩ¢Âºè„Åß„ÄÅÂ∞ÇÈñÄÁî®Ë™û„Å®Ê¶ÇÂøµ„ÇíÊ≠£Á¢∫„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
            'patent': "ÁâπË®±ÊñáÊõ∏ÂΩ¢Âºè„Åß„ÄÅÊäÄË°ìÁöÑË©≥Á¥∞„Å®Áô∫ÊòéÂÜÖÂÆπ„ÇíÊ≠£Á¢∫„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        }
        
        instruction = doc_instructions.get(doc_type, "ÊäÄË°ìÊñáÊõ∏„Å®„Åó„Å¶Ê≠£Á¢∫„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
        
        prompt = f"""[INST] ‰ª•‰∏ã„ÅÆËã±Ë™ûÊäÄË°ìÊñáÊõ∏„ÇíÊó•Êú¨Ë™û„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

ÁøªË®≥ÊñπÈáù:
‚Ä¢ {instruction}
‚Ä¢ ÊäÄË°ìÁî®Ë™û„ÅØÊ≠£Á¢∫„Å™Êó•Êú¨Ë™ûÂ∞ÇÈñÄÁî®Ë™û„Çí‰ΩøÁî®
‚Ä¢ Êï∞ÂÄ§„ÉªÂçò‰Ωç„ÉªË®òÂè∑„ÅØÂ§âÊõ¥„Åó„Å™„ÅÑ
‚Ä¢ ÊñáÊõ∏ÊßãÈÄ†„Çí‰øùÊåÅ
‚Ä¢ Ëá™ÁÑ∂„ÅßË™≠„Åø„ÇÑ„Åô„ÅÑÊó•Êú¨Ë™û„Å´ÁøªË®≥

Ëã±Ë™ûÊäÄË°ìÊñáÊõ∏:
{text[:2000]}

Êó•Êú¨Ë™ûÁøªË®≥: [/INST]"""
        
        return prompt
    
    def _calculate_confidence(self, translation: str, original: str) -> float:
        """Calculate translation confidence score."""
        if not translation or translation.startswith("‚ùå"):
            return 0.0
        
        # Basic quality metrics
        translation_length = len(translation)
        original_length = len(original)
        
        if translation_length == 0:
            return 0.0
        
        # Length ratio check (good translation should be reasonable length)
        length_ratio = translation_length / original_length
        
        if 0.5 <= length_ratio <= 2.0:
            confidence = 0.8
        elif 0.3 <= length_ratio <= 3.0:
            confidence = 0.6
        else:
            confidence = 0.4
        
        # Check for Japanese content
        japanese_chars = sum(1 for char in translation if '\u3040' <= char <= '\u309F' or '\u30A0' <= char <= '\u30FF' or '\u4E00' <= char <= '\u9FAF')
        if japanese_chars > len(translation) * 0.3:
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about the loaded model."""
        return {
            'model_path': str(self.model_path),
            'model_loaded': self.is_loaded,
            'model_name': self.model_path.name if self.model_path.exists() else 'Not found',
            'llm_available': llm_available,
            'recommended_ram': '8-12GB'
        }
