#!/usr/bin/env python3
"""
Quality Comparison Client
API vs GUIå‡¦ç†å“è³ªã®å®Ÿè¨¼æ¯”è¼ƒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
"""

import requests
import time
import json
from typing import Dict, Any

class QualityComparisonClient:
    """å“è³ªæ¯”è¼ƒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.original_api = "http://localhost:8000"
        self.enhanced_api = "http://localhost:8001"
    
    def compare_processing_quality(self, text: str) -> Dict[str, Any]:
        """å‡¦ç†å“è³ªã‚’æ¯”è¼ƒ"""
        print("ğŸ”¬ å‡¦ç†å“è³ªæ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 50)
        
        results = {
            "original_api": None,
            "enhanced_basic": None,
            "enhanced_enhanced": None,
            "enhanced_academic": None
        }
        
        # 1. ã‚ªãƒªã‚¸ãƒŠãƒ«APIï¼ˆåŸºæœ¬å‡¦ç†ï¼‰
        print("\nğŸŒ ã‚ªãƒªã‚¸ãƒŠãƒ«APIï¼ˆãƒãƒ¼ãƒˆ8000ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ:")
        try:
            original_payload = {
                "content": text,
                "language": "ja",
                "max_length": 150,
                "use_llm": False,
                "auto_detect_language": True,
                "output_format": "markdown"
            }
            
            start_time = time.time()
            response = requests.post(
                f"{self.original_api}/api/v1/process",
                json=original_payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                processing_time = time.time() - start_time
                
                results["original_api"] = {
                    "status": result.get("status", "unknown"),
                    "summary": result.get("summary", ""),
                    "processing_time": processing_time,
                    "summary_length": len(result.get("summary", "")),
                    "api_processing_time": result.get("metadata", {}).get("processing_time", 0)
                }
                
                print(f"  âœ… æˆåŠŸ: {result.get('status')}")
                print(f"  â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
                print(f"  ğŸ“ è¦ç´„é•·: {len(result.get('summary', ''))} æ–‡å­—")
                print(f"  ğŸ“„ è¦ç´„: {result.get('summary', '')[:100]}...")
                
            else:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                results["original_api"] = {"error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            print(f"  âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            results["original_api"] = {"error": str(e)}
        
        # 2. Enhanced API - Basic Mode
        print("\nğŸš€ Enhanced API - Basic Modeï¼ˆãƒãƒ¼ãƒˆ8001ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ:")
        results["enhanced_basic"] = self._test_enhanced_mode(text, "basic")
        
        # 3. Enhanced API - Enhanced Mode
        print("\nâ­ Enhanced API - Enhanced Modeï¼ˆãƒãƒ¼ãƒˆ8001ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ:")
        results["enhanced_enhanced"] = self._test_enhanced_mode(text, "enhanced")
        
        # 4. Enhanced API - Academic Mode
        print("\nğŸ“ Enhanced API - Academic Modeï¼ˆãƒãƒ¼ãƒˆ8001ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ:")
        results["enhanced_academic"] = self._test_enhanced_mode(text, "academic")
        
        return results
    
    def _test_enhanced_mode(self, text: str, mode: str) -> Dict[str, Any]:
        """Enhanced APIã®ç‰¹å®šãƒ¢ãƒ¼ãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ"""
        try:
            payload = {
                "content": text,
                "language": "ja",
                "max_length": 150,
                "processing_mode": mode,
                "use_llm": True,
                "enable_translation": True,
                "detect_technical_terms": True,
                "quality_assessment": True,
                "output_format": "academic",
                "include_metadata": True,
                "auto_detect_language": True
            }
            
            start_time = time.time()
            response = requests.post(
                f"{self.enhanced_api}/api/v2/process",
                json=payload,
                timeout=60
            )
            
            total_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                
                print(f"  âœ… æˆåŠŸ: {result.get('status')}")
                print(f"  â±ï¸ å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
                print(f"  ğŸ“ è¦ç´„é•·: {len(result.get('summary', ''))} æ–‡å­—")
                print(f"  ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {result.get('quality_score', 'N/A')}")
                print(f"  ğŸ·ï¸ æŠ€è¡“ç”¨èª: {len(result.get('technical_terms', []))}å€‹")
                print(f"  ğŸ“„ è¦ç´„: {result.get('summary', '')[:100]}...")
                
                return {
                    "status": result.get("status"),
                    "summary": result.get("summary", ""),
                    "processing_time": total_time,
                    "quality_score": result.get("quality_score"),
                    "technical_terms": result.get("technical_terms", []),
                    "translation_quality": result.get("translation_quality"),
                    "metadata": result.get("metadata", {}),
                    "summary_length": len(result.get("summary", ""))
                }
                
            else:
                error_msg = f"HTTP {response.status_code}"
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {error_msg}")
                return {"error": error_msg}
                
        except Exception as e:
            print(f"  âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def generate_quality_report(self, results: Dict[str, Any], original_text: str) -> str:
        """å“è³ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = """
# ğŸ“Š LocalLLM API å“è³ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
- **åŸæ–‡é•·**: {original_length} æ–‡å­—
- **ãƒ†ã‚¹ãƒˆæ—¥æ™‚**: {timestamp}

## ğŸ”¬ å‡¦ç†çµæœæ¯”è¼ƒ

""".format(
            original_length=len(original_text),
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        # å„çµæœã‚’æ¯”è¼ƒ
        modes = [
            ("ğŸŒ ã‚ªãƒªã‚¸ãƒŠãƒ«API", "original_api"),
            ("ğŸš€ Enhanced Basic", "enhanced_basic"),
            ("â­ Enhanced Enhanced", "enhanced_enhanced"),
            ("ğŸ“ Enhanced Academic", "enhanced_academic")
        ]
        
        for mode_name, mode_key in modes:
            result = results.get(mode_key)
            if result and "error" not in result:
                report += f"""
### {mode_name}

- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {result.get('status', 'N/A')}
- **å‡¦ç†æ™‚é–“**: {result.get('processing_time', 0):.2f}ç§’
- **è¦ç´„é•·**: {result.get('summary_length', 0)} æ–‡å­—
- **å“è³ªã‚¹ã‚³ã‚¢**: {result.get('quality_score', 'N/A')}
- **æŠ€è¡“ç”¨èªæ•°**: {len(result.get('technical_terms', []))}å€‹
- **ç¿»è¨³å“è³ª**: {result.get('translation_quality', 'N/A')}

**è¦ç´„å†…å®¹**:
```
{summary}
```

"""
                summary = result.get('summary', '')[:300]
                summary += "..." if len(result.get('summary', '')) > 300 else ""
                report = report.format(summary=summary)
                
            elif result and "error" in result:
                report += f"""
### {mode_name}

âŒ **ã‚¨ãƒ©ãƒ¼**: {result['error']}

"""
            else:
                report += f"""
### {mode_name}

âš ï¸ **ãƒ†ã‚¹ãƒˆæœªå®Ÿè¡Œ**

"""
        
        # ç·åˆè©•ä¾¡
        report += """
## ğŸ“ˆ ç·åˆè©•ä¾¡

| é …ç›® | ã‚ªãƒªã‚¸ãƒŠãƒ«API | Enhanced Basic | Enhanced Enhanced | Enhanced Academic |
|------|---------------|----------------|-------------------|-------------------|
"""
        
        # è©•ä¾¡è¡¨ã‚’ç”Ÿæˆ
        metrics = ["å‡¦ç†æ™‚é–“", "è¦ç´„å“è³ª", "æŠ€è¡“å¯¾å¿œ", "ç·åˆè©•ä¾¡"]
        for metric in metrics:
            row = f"| {metric} |"
            for mode_name, mode_key in modes:
                result = results.get(mode_key)
                if result and "error" not in result:
                    if metric == "å‡¦ç†æ™‚é–“":
                        score = "â­â­â­â­â­" if result.get('processing_time', 999) < 5 else "â­â­â­"
                    elif metric == "è¦ç´„å“è³ª":
                        quality = result.get('quality_score', 0)
                        if quality > 0.8:
                            score = "â­â­â­â­â­"
                        elif quality > 0.6:
                            score = "â­â­â­â­"
                        else:
                            score = "â­â­â­"
                    elif metric == "æŠ€è¡“å¯¾å¿œ":
                        terms = len(result.get('technical_terms', []))
                        score = "â­â­â­â­â­" if terms > 3 else ("â­â­â­" if terms > 0 else "â­")
                    else:  # ç·åˆè©•ä¾¡
                        score = "â­â­â­â­â­" if mode_key.startswith("enhanced") else "â­â­â­"
                else:
                    score = "âŒ"
                row += f" {score} |"
            report += row + "\n"
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ LocalLLM API å“è³ªæ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    test_text = """
    Artificial Intelligence (AI) and Machine Learning (ML) technologies have revolutionized 
    modern computing systems. Large Language Models (LLMs) like GPT and BERT have shown 
    remarkable capabilities in natural language processing tasks including text summarization, 
    translation, and content generation. These neural networks utilize transformer architectures 
    with attention mechanisms to understand contextual relationships in text data. The integration 
    of AI APIs in business applications has enabled automated document processing, intelligent 
    search systems, and real-time language translation services. Recent advances in model 
    optimization techniques have made it possible to deploy these sophisticated algorithms 
    on edge computing devices with limited computational resources.
    """
    
    # å“è³ªæ¯”è¼ƒå®Ÿè¡Œ
    client = QualityComparisonClient()
    
    print("âš ï¸ æ³¨æ„: ä»¥ä¸‹ã®APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:")
    print("  - ã‚ªãƒªã‚¸ãƒŠãƒ«API: http://localhost:8000")
    print("  - Enhanced API: http://localhost:8001")
    print()
    
    results = client.compare_processing_quality(test_text)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = client.generate_quality_report(results, test_text)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_file = Path("output") / "quality_comparison_report.md"
    report_file.parent.mkdir(exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“Š å“è³ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")
    print("\n" + "=" * 60)
    print("ğŸ¯ çµè«–:")
    
    # ç°¡å˜ãªçµè«–ã‚’è¡¨ç¤º
    successful_results = {k: v for k, v in results.items() if v and "error" not in v}
    
    if len(successful_results) > 1:
        print("  âœ… è¤‡æ•°ã®APIãƒ¢ãƒ¼ãƒ‰ã§æ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # å“è³ªã‚¹ã‚³ã‚¢æ¯”è¼ƒ
        quality_scores = {k: v.get('quality_score', 0) for k, v in successful_results.items() if v.get('quality_score')}
        if quality_scores:
            best_quality = max(quality_scores.items(), key=lambda x: x[1])
            print(f"  ğŸ† æœ€é«˜å“è³ª: {best_quality[0]} (ã‚¹ã‚³ã‚¢: {best_quality[1]:.2f})")
        
        # å‡¦ç†æ™‚é–“æ¯”è¼ƒ
        processing_times = {k: v.get('processing_time', 999) for k, v in successful_results.items()}
        if processing_times:
            fastest = min(processing_times.items(), key=lambda x: x[1])
            print(f"  âš¡ æœ€é«˜é€Ÿåº¦: {fastest[0]} ({fastest[1]:.2f}ç§’)")
            
    else:
        print("  âš ï¸ ååˆ†ãªæ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        print("  ğŸ’¡ APIã‚µãƒ¼ãƒãƒ¼ãŒæ­£å¸¸ã«èµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    from pathlib import Path
    main()
