"""
Academic Output Formatter
åŒ…æ‹¬çš„ãªå­¦è¡“æ–‡æ›¸ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”Ÿæˆ
"""

from pathlib import Path
from typing import Dict, Any, List
import json
from datetime import datetime

class AcademicOutputFormatter:
    """å­¦è¡“æ–‡æ›¸ã®åŒ…æ‹¬çš„å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.template_sections = {
            'structure': 'ğŸ“Š æ–‡æ›¸æ§‹é€ åˆ†æ',
            'technical': 'ğŸ”¬ æŠ€è¡“çš„è©³ç´°',
            'findings': 'ğŸ’¡ ä¸»è¦ãªç™ºè¦‹',
            'applications': 'ğŸ¯ å¿œç”¨åˆ†é‡',
            'limitations': 'âš ï¸ åˆ¶ç´„ãƒ»é™ç•Œ',
            'metadata': 'ğŸ“‹ æ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿'
        }
    
    def format_technical_japanese_summary(self, translation_data: Dict[str, Any]) -> str:
        """
        æŠ€è¡“æ–‡æ›¸ã®è‹±æ—¥ç¿»è¨³çµæœã‚’åŒ…æ‹¬çš„ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            translation_data: æŠ€è¡“ç¿»è¨³å‡¦ç†çµæœè¾æ›¸
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ—¥æœ¬èªæŠ€è¡“è¦ç´„
        """
        output_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        doc_type_jp = {
            'datasheet': 'ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ',
            'academic_paper': 'å­¦è¡“è«–æ–‡',
            'technical_report': 'æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆ',
            'manual': 'æŠ€è¡“ãƒãƒ‹ãƒ¥ã‚¢ãƒ«',
            'patent': 'ç‰¹è¨±æ–‡æ›¸',
            'technical_document': 'æŠ€è¡“æ–‡æ›¸'
        }.get(translation_data.get('document_type', 'unknown'), 'æŠ€è¡“æ–‡æ›¸')
        
        output_lines.append(f"# ğŸ“š {doc_type_jp}ç¿»è¨³ãƒ¬ãƒãƒ¼ãƒˆ")
        output_lines.append(f"**å‡¦ç†æ—¥æ™‚:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # å“è³ªæƒ…å ±
        quality_jp = {
            'good': 'è‰¯å¥½',
            'fair': 'æ™®é€š',
            'poor': 'è¦æ”¹å–„'
        }.get(translation_data.get('translation_quality', 'unknown'), 'ä¸æ˜')
        
        confidence_score = translation_data.get('quality_score', translation_data.get('confidence_score', 0.0))
        confidence_percent = f"{confidence_score * 100:.1f}%"
        
        processing_time = translation_data.get('processing_time', 0)
        
        output_lines.append(f"**ç¿»è¨³å“è³ª:** {quality_jp} (ä¿¡é ¼åº¦: {confidence_percent})")
        output_lines.append(f"**å‡¦ç†æ™‚é–“:** {processing_time:.2f}ç§’")
        output_lines.append("")
        
        # ãƒ¡ã‚¤ãƒ³ç¿»è¨³å†…å®¹
        output_lines.append("## ğŸ“„ æ—¥æœ¬èªç¿»è¨³")
        main_translation = translation_data.get('japanese_translation', 'ç¿»è¨³çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚')
        output_lines.append(main_translation)
        output_lines.append("")
        
        # ä¸»è¦è²¢çŒ®
        if translation_data.get('main_contribution'):
            output_lines.append("## ğŸ’¡ ä¸»è¦è²¢çŒ®ãƒ»ç‰¹å¾´")
            output_lines.append(translation_data['main_contribution'])
            output_lines.append("")
        
        # ä¸»è¦ç™ºè¦‹
        key_findings = translation_data.get('key_findings', [])
        if key_findings:
            output_lines.append("## ğŸ” ä¸»è¦ç™ºè¦‹ãƒ»çµæœ")
            for i, finding in enumerate(key_findings[:5], 1):
                output_lines.append(f"{i}. {finding}")
            output_lines.append("")
        
        # æŠ€è¡“è©³ç´°
        technical_details = translation_data.get('technical_details', [])
        if technical_details:
            output_lines.append("## âš™ï¸ æŠ€è¡“è©³ç´°")
            for i, detail in enumerate(technical_details[:5], 1):
                output_lines.append(f"**è©³ç´°{i}:** {detail}")
            output_lines.append("")
        
        # å®Ÿç”¨çš„å¿œç”¨
        applications = translation_data.get('practical_applications', [])
        if applications:
            output_lines.append("## ğŸ¯ å®Ÿç”¨çš„å¿œç”¨ãƒ»ç”¨é€”")
            for i, app in enumerate(applications[:3], 1):
                output_lines.append(f"- {app}")
            output_lines.append("")
        
        # æ•°å­¦çš„æ¦‚å¿µ
        math_concepts = translation_data.get('mathematical_concepts', [])
        if math_concepts:
            output_lines.append("## ğŸ§® æ•°å­¦çš„æ¦‚å¿µãƒ»æ‰‹æ³•")
            for concept in math_concepts[:5]:
                output_lines.append(f"- {concept}")
            output_lines.append("")
        
        # æ¤œå‡ºã•ã‚ŒãŸæŠ€è¡“ç”¨èª
        technical_terms = translation_data.get('technical_terms_found', [])
        if technical_terms:
            output_lines.append("## ğŸ”¤ æ¤œå‡ºæŠ€è¡“ç”¨èª")
            terms_display = ", ".join(technical_terms[:10])
            if len(technical_terms) > 10:
                terms_display += f" ãªã©ï¼ˆ{len(technical_terms)}èªæ¤œå‡ºï¼‰"
            output_lines.append(terms_display)
            output_lines.append("")
        
        # æ‰‹æ³•è¦ç´„
        if translation_data.get('methodology_summary'):
            output_lines.append("## ğŸ“‹ æ‰‹æ³•ãƒ»æ–¹æ³•è«–è¦ç´„")
            output_lines.append(translation_data['methodology_summary'])
            output_lines.append("")
        
        # å‡¦ç†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = translation_data.get('processing_metadata', {})
        if metadata:
            output_lines.append("## ğŸ“Š å‡¦ç†æƒ…å ±")
            output_lines.append(f"**æŠ€è¡“ãƒ¬ãƒ™ãƒ«:** {metadata.get('technical_level', 'ä¸æ˜')}")
            output_lines.append(f"**æ–‡æ›¸åˆ†é¡:** {metadata.get('document_classification', 'ä¸æ˜')}")
            output_lines.append(f"**æ¤œå‡ºç”¨èªæ•°:** {metadata.get('terms_detected', 0)}èª")
            if metadata.get('file_path'):
                output_lines.append(f"**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹:** {metadata['file_path']}")
            output_lines.append("")
        
        return "\n".join(output_lines)
    
    def format_comprehensive_summary(self, summary_data: Dict[str, Any], 
                                   include_metadata: bool = False) -> str:
        """åŒ…æ‹¬çš„ãªå­¦è¡“ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        output_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        output_lines.append("# ğŸ“š å­¦è¡“æ–‡æ›¸è§£æãƒ¬ãƒãƒ¼ãƒˆ")
        output_lines.append(f"**ç”Ÿæˆæ—¥æ™‚:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output_lines.append("")
        
        # åŸºæœ¬æƒ…å ±
        if 'basic_info' in summary_data:
            basic = summary_data['basic_info']
            output_lines.append("## ğŸ“„ åŸºæœ¬æƒ…å ±")
            if 'title' in basic:
                output_lines.append(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {basic['title']}")
            if 'document_type' in basic:
                output_lines.append(f"**æ–‡æ›¸ç¨®åˆ¥:** {basic['document_type']}")
            if 'language' in basic:
                output_lines.append(f"**è¨€èª:** {basic['language']}")
            output_lines.append("")
        
        # è¦ç´„
        if 'summary' in summary_data:
            output_lines.append("## ğŸ“ è¦ç´„")
            output_lines.append(summary_data['summary'])
            output_lines.append("")
        
        # æ§‹é€ åˆ†æ
        if 'structure_analysis' in summary_data:
            structure = summary_data['structure_analysis']
            output_lines.append(f"## {self.template_sections['structure']}")
            
            if 'sections' in structure:
                output_lines.append("### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆ")
                for i, section in enumerate(structure['sections'], 1):
                    output_lines.append(f"{i}. {section}")
                output_lines.append("")
            
            if 'content_organization' in structure:
                output_lines.append("### ğŸ—‚ï¸ å†…å®¹æ§‹æˆ")
                output_lines.append(structure['content_organization'])
                output_lines.append("")
            
            if 'document_flow' in structure:
                output_lines.append("### ğŸ”„ è«–ç†çš„æµã‚Œ")
                output_lines.append(structure['document_flow'])
                output_lines.append("")
        
        # æŠ€è¡“çš„è©³ç´°
        if 'technical_details' in summary_data:
            technical = summary_data['technical_details']
            output_lines.append(f"## {self.template_sections['technical']}")
            
            if 'methodologies' in technical:
                output_lines.append("### ğŸ”¬ æ‰‹æ³•ãƒ»æ–¹æ³•è«–")
                if isinstance(technical['methodologies'], list):
                    for method in technical['methodologies']:
                        output_lines.append(f"- {method}")
                else:
                    output_lines.append(technical['methodologies'])
                output_lines.append("")
            
            if 'technologies' in technical:
                output_lines.append("### ğŸ’» æŠ€è¡“ãƒ»æŠ€è¡“ä»•æ§˜")
                if isinstance(technical['technologies'], list):
                    for tech in technical['technologies']:
                        output_lines.append(f"- {tech}")
                else:
                    output_lines.append(technical['technologies'])
                output_lines.append("")
            
            if 'data_analysis' in technical:
                output_lines.append("### ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æ")
                output_lines.append(technical['data_analysis'])
                output_lines.append("")
        
        # ä¸»è¦ãªç™ºè¦‹
        if 'key_findings' in summary_data:
            findings = summary_data['key_findings']
            output_lines.append(f"## {self.template_sections['findings']}")
            
            if 'main_results' in findings:
                output_lines.append("### ğŸ¯ ä¸»ãªçµæœ")
                if isinstance(findings['main_results'], list):
                    for i, result in enumerate(findings['main_results'], 1):
                        output_lines.append(f"{i}. {result}")
                else:
                    output_lines.append(findings['main_results'])
                output_lines.append("")
            
            if 'innovations' in findings:
                output_lines.append("### âœ¨ é©æ–°çš„è¦ç´ ")
                if isinstance(findings['innovations'], list):
                    for innovation in findings['innovations']:
                        output_lines.append(f"- {innovation}")
                else:
                    output_lines.append(findings['innovations'])
                output_lines.append("")
            
            if 'significance' in findings:
                output_lines.append("### ğŸŒŸ æ„ç¾©ãƒ»é‡è¦æ€§")
                output_lines.append(findings['significance'])
                output_lines.append("")
        
        # å¿œç”¨åˆ†é‡
        if 'applications' in summary_data:
            applications = summary_data['applications']
            output_lines.append(f"## {self.template_sections['applications']}")
            
            if 'practical_uses' in applications:
                output_lines.append("### ğŸ”§ å®Ÿç”¨çš„å¿œç”¨")
                if isinstance(applications['practical_uses'], list):
                    for use in applications['practical_uses']:
                        output_lines.append(f"- {use}")
                else:
                    output_lines.append(applications['practical_uses'])
                output_lines.append("")
            
            if 'industries' in applications:
                output_lines.append("### ğŸ­ å¯¾è±¡ç”£æ¥­")
                if isinstance(applications['industries'], list):
                    for industry in applications['industries']:
                        output_lines.append(f"- {industry}")
                else:
                    output_lines.append(applications['industries'])
                output_lines.append("")
            
            if 'future_potential' in applications:
                output_lines.append("### ğŸš€ å°†æ¥ã®å¯èƒ½æ€§")
                output_lines.append(applications['future_potential'])
                output_lines.append("")
        
        # åˆ¶ç´„ãƒ»é™ç•Œ
        if 'limitations' in summary_data:
            limitations = summary_data['limitations']
            output_lines.append(f"## {self.template_sections['limitations']}")
            
            if 'technical_limitations' in limitations:
                output_lines.append("### âš™ï¸ æŠ€è¡“çš„åˆ¶ç´„")
                if isinstance(limitations['technical_limitations'], list):
                    for limitation in limitations['technical_limitations']:
                        output_lines.append(f"- {limitation}")
                else:
                    output_lines.append(limitations['technical_limitations'])
                output_lines.append("")
            
            if 'scope_limitations' in limitations:
                output_lines.append("### ğŸ“ é©ç”¨ç¯„å›²ã®åˆ¶é™")
                output_lines.append(limitations['scope_limitations'])
                output_lines.append("")
            
            if 'future_work' in limitations:
                output_lines.append("### ğŸ”® ä»Šå¾Œã®èª²é¡Œ")
                if isinstance(limitations['future_work'], list):
                    for work in limitations['future_work']:
                        output_lines.append(f"- {work}")
                else:
                    output_lines.append(limitations['future_work'])
                output_lines.append("")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if include_metadata and 'metadata' in summary_data:
            metadata = summary_data['metadata']
            output_lines.append(f"## {self.template_sections['metadata']}")
            
            if 'file_info' in metadata:
                output_lines.append("### ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
                file_info = metadata['file_info']
                for key, value in file_info.items():
                    output_lines.append(f"- **{key}:** {value}")
                output_lines.append("")
            
            if 'processing_info' in metadata:
                output_lines.append("### âš™ï¸ å‡¦ç†æƒ…å ±")
                proc_info = metadata['processing_info']
                for key, value in proc_info.items():
                    output_lines.append(f"- **{key}:** {value}")
                output_lines.append("")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        output_lines.append("---")
        output_lines.append("*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯å­¦è¡“ç‰¹åŒ–æ–‡æ›¸å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*")
        
        return "\n".join(output_lines)
    
    def create_structured_summary(self, academic_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å­¦è¡“åˆ†æçµæœã‹ã‚‰æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        
        structured_summary = {
            'basic_info': {
                'title': academic_analysis.get('title', 'æœªç‰¹å®š'),
                'document_type': academic_analysis.get('document_type', 'generic'),
                'language': academic_analysis.get('language', 'æ—¥æœ¬èª'),
                'analysis_depth': academic_analysis.get('analysis_depth', 'standard')
            },
            'summary': academic_analysis.get('summary', ''),
            'structure_analysis': self._extract_structure_info(academic_analysis),
            'technical_details': self._extract_technical_info(academic_analysis),
            'key_findings': self._extract_findings_info(academic_analysis),
            'applications': self._extract_applications_info(academic_analysis),
            'limitations': self._extract_limitations_info(academic_analysis),
            'metadata': {
                'file_info': academic_analysis.get('file_info', {}),
                'processing_info': {
                    'processed_at': datetime.now().isoformat(),
                    'processor': 'AcademicDocumentProcessor',
                    'version': '1.0'
                }
            }
        }
        
        return structured_summary
    
    def _extract_structure_info(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ§‹é€ æƒ…å ±ã‚’æŠ½å‡º"""
        structure = {}
        
        if 'sections' in analysis:
            structure['sections'] = analysis['sections']
        
        if 'content_organization' in analysis:
            structure['content_organization'] = analysis['content_organization']
        elif 'structure' in analysis:
            structure['content_organization'] = analysis['structure']
        
        if 'document_flow' in analysis:
            structure['document_flow'] = analysis['document_flow']
        
        return structure
    
    def _extract_technical_info(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æŠ€è¡“æƒ…å ±ã‚’æŠ½å‡º"""
        technical = {}
        
        if 'methodologies' in analysis:
            technical['methodologies'] = analysis['methodologies']
        elif 'methods' in analysis:
            technical['methodologies'] = analysis['methods']
        
        if 'technologies' in analysis:
            technical['technologies'] = analysis['technologies']
        elif 'technical_specs' in analysis:
            technical['technologies'] = analysis['technical_specs']
        
        if 'data_analysis' in analysis:
            technical['data_analysis'] = analysis['data_analysis']
        
        return technical
    
    def _extract_findings_info(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç™ºè¦‹æƒ…å ±ã‚’æŠ½å‡º"""
        findings = {}
        
        if 'key_findings' in analysis:
            findings['main_results'] = analysis['key_findings']
        elif 'results' in analysis:
            findings['main_results'] = analysis['results']
        
        if 'innovations' in analysis:
            findings['innovations'] = analysis['innovations']
        elif 'novel_aspects' in analysis:
            findings['innovations'] = analysis['novel_aspects']
        
        if 'significance' in analysis:
            findings['significance'] = analysis['significance']
        elif 'importance' in analysis:
            findings['significance'] = analysis['importance']
        
        return findings
    
    def _extract_applications_info(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¿œç”¨æƒ…å ±ã‚’æŠ½å‡º"""
        applications = {}
        
        if 'applications' in analysis:
            applications['practical_uses'] = analysis['applications']
        elif 'use_cases' in analysis:
            applications['practical_uses'] = analysis['use_cases']
        
        if 'industries' in analysis:
            applications['industries'] = analysis['industries']
        elif 'target_sectors' in analysis:
            applications['industries'] = analysis['target_sectors']
        
        if 'future_potential' in analysis:
            applications['future_potential'] = analysis['future_potential']
        
        return applications
    
    def _extract_limitations_info(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶ç´„æƒ…å ±ã‚’æŠ½å‡º"""
        limitations = {}
        
        if 'limitations' in analysis:
            limitations['technical_limitations'] = analysis['limitations']
        elif 'constraints' in analysis:
            limitations['technical_limitations'] = analysis['constraints']
        
        if 'scope_limitations' in analysis:
            limitations['scope_limitations'] = analysis['scope_limitations']
        elif 'scope' in analysis:
            limitations['scope_limitations'] = analysis['scope']
        
        if 'future_work' in analysis:
            limitations['future_work'] = analysis['future_work']
        elif 'improvements' in analysis:
            limitations['future_work'] = analysis['improvements']
        
        return limitations
    
    def save_formatted_output(self, formatted_content: str, output_path: Path) -> bool:
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿å†…å®¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(formatted_content)
            
            return True
        except Exception as e:
            print(f"å‡ºåŠ›ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
